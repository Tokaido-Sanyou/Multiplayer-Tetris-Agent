#!/usr/bin/env python3
"""
Test script for the enhanced Multi-Attempt Goal-Focused Training with HER
Tests the new multi-attempt mechanism with Hindsight Experience Replay (HER) using randomized future goals
"""

import sys
import os
import torch
import numpy as np

# Add path for imports
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from localMultiplayerTetris.rl_utils.unified_trainer import UnifiedTrainer, TrainingConfig
from localMultiplayerTetris.tetris_env import TetrisEnv

def test_multi_attempt_training():
    print("üß™ Testing Enhanced Multi-Attempt Goal-Focused Training with HER")
    print("="*70)
    
    # Create minimal config for testing
    config = TrainingConfig()
    config.num_batches = 1  # Just test one batch
    config.exploration_episodes = 2  # Minimal exploration
    config.exploitation_episodes = 2  # Test multi-attempt exploitation
    config.eval_episodes = 1  # Minimal evaluation
    config.exploration_mode = 'deterministic'  # Use deterministic for predictable results
    config.visualize = False  # No visualization for testing
    
    print(f"üìã Test Configuration:")
    print(f"   ‚Ä¢ Batches: {config.num_batches}")
    print(f"   ‚Ä¢ Exploration episodes: {config.exploration_episodes}")
    print(f"   ‚Ä¢ Exploitation episodes: {config.exploitation_episodes}")
    print(f"   ‚Ä¢ Exploration mode: {config.exploration_mode}")
    print(f"   ‚Ä¢ Device: {config.device}")
    
    try:
        # Initialize trainer
        print(f"\nüîß Initializing Enhanced Trainer...")
        trainer = UnifiedTrainer(config)
        
        # Test Phase 1: Exploration
        print(f"\nüîç Testing Phase 1: Exploration...")
        trainer.phase_1_exploration(0)
        exploration_data_count = len(trainer.exploration_data)
        print(f"   ‚úÖ Generated {exploration_data_count} exploration data points")
        
        if exploration_data_count == 0:
            print(f"   ‚ö†Ô∏è  No exploration data generated - skipping remaining phases")
            return False
        
        # Test Phase 2: State Learning
        print(f"\nüéØ Testing Phase 2: State Learning...")
        trainer.phase_2_state_learning(0)
        print(f"   ‚úÖ State model training completed")
        
        # Test Phase 3: Reward Prediction
        print(f"\nüîÆ Testing Phase 3: Reward Prediction...")
        trainer.phase_3_reward_prediction(0)
        print(f"   ‚úÖ Reward predictor training completed")
        
        # Test Phase 4: Multi-Attempt Exploitation
        print(f"\nüéÆ Testing Phase 4: Multi-Attempt Goal-Focused Exploitation...")
        old_buffer_size = len(trainer.experience_buffer)
        trainer.phase_4_exploitation(0)
        new_buffer_size = len(trainer.experience_buffer)
        
        # Check multi-attempt statistics
        exploitation_stats = trainer.batch_stats.get('exploitation', {})
        multi_attempt_enabled = exploitation_stats.get('multi_attempt_enabled', False)
        avg_attempts = exploitation_stats.get('avg_attempts_per_episode', 0)
        step_goal_success_rate = exploitation_stats.get('step_goal_success_rate', 0)
        episode_goal_success_rate = exploitation_stats.get('episode_goal_success_rate', 0)
        hindsight_trajectories = exploitation_stats.get('hindsight_trajectories', 0)
        total_hindsight_experiences = exploitation_stats.get('total_hindsight_experiences', 0)
        
        print(f"   ‚úÖ Multi-attempt exploitation completed")
        print(f"   üìä Multi-attempt enabled: {multi_attempt_enabled}")
        print(f"   üìä Average attempts per episode: {avg_attempts:.1f}")
        print(f"   üìä Step-level goal success rate: {step_goal_success_rate:.3f}")
        print(f"   üìä Episode-level goal success rate: {episode_goal_success_rate:.3f}")
        print(f"   üìä Hindsight trajectories created: {hindsight_trajectories}")
        print(f"   üìä Total hindsight experiences: {total_hindsight_experiences}")
        print(f"   üìä Experience buffer growth: {old_buffer_size} ‚Üí {new_buffer_size}")
        
        # Test Phase 5: PPO Training
        print(f"\nüèãÔ∏è Testing Phase 5: PPO with Hindsight...")
        if len(trainer.experience_buffer) >= trainer.config.min_buffer_size:
            trainer.phase_5_ppo_training(0)
            print(f"   ‚úÖ PPO training with hindsight completed")
        else:
            print(f"   ‚ö†Ô∏è  Insufficient experience for PPO training ({len(trainer.experience_buffer)} < {trainer.config.min_buffer_size})")
        
        # Test Phase 6: Evaluation
        print(f"\nüìä Testing Phase 6: Evaluation...")
        trainer.phase_6_evaluation(0)
        print(f"   ‚úÖ Evaluation completed")
        
        # Print comprehensive test summary
        print(f"\nüéØ Enhanced Training Test Summary:")
        trainer.print_batch_summary(0)
        
        # Verify enhanced multi-attempt + HER features
        success_indicators = []
        
        if multi_attempt_enabled:
            success_indicators.append("‚úÖ Multi-attempt mechanism enabled")
        else:
            success_indicators.append("‚ùå Multi-attempt mechanism not enabled")
        
        if avg_attempts >= 2.5:  # Should be close to 3 attempts per episode
            success_indicators.append("‚úÖ Multiple attempts per episode detected")
        else:
            success_indicators.append("‚ùå Insufficient attempts per episode")
        
        if total_hindsight_experiences > avg_attempts * 0.5:  # Should have hindsight for significant portion of attempts
            success_indicators.append("‚úÖ ALL-ATTEMPT HER (Hindsight Experience Replay) working")
        else:
            success_indicators.append("‚ùå ALL-ATTEMPT HER (Hindsight Experience Replay) not working")
        
        if new_buffer_size > old_buffer_size:
            success_indicators.append("‚úÖ Experience buffer populated with hindsight")
        else:
            success_indicators.append("‚ùå Experience buffer not growing")
        
        # Additional HER-specific checks
        if step_goal_success_rate > 0 or episode_goal_success_rate > 0:
            success_indicators.append("‚úÖ Goal achievement detected (step or episode level)")
        else:
            success_indicators.append("‚ùå No goal achievement detected")
        
        print(f"\nüîç Enhanced Test Results:")
        for indicator in success_indicators:
            print(f"   {indicator}")
        
        # Overall success
        success_count = sum(1 for ind in success_indicators if ind.startswith("‚úÖ"))
        total_checks = len(success_indicators)
        
        print(f"\nüèÜ Overall Test Result: {success_count}/{total_checks} checks passed")
        print(f"üìä Detailed Metrics:")
        print(f"   ‚Ä¢ Multi-attempt: {multi_attempt_enabled}")
        print(f"   ‚Ä¢ Attempts/episode: {avg_attempts:.1f}")
        print(f"   ‚Ä¢ Step success rate: {step_goal_success_rate:.3f} ({step_goal_success_rate*100:.1f}%)")
        print(f"   ‚Ä¢ Episode success rate: {episode_goal_success_rate:.3f} ({episode_goal_success_rate*100:.1f}%)")
        print(f"   ‚Ä¢ HER trajectories: {hindsight_trajectories}")
        print(f"   ‚Ä¢ Total hindsight experiences: {total_hindsight_experiences}")
        print(f"   ‚Ä¢ Buffer growth: {old_buffer_size} ‚Üí {new_buffer_size}")
        print(f"   ‚Ä¢ Hindsight coverage: {total_hindsight_experiences / max(1, avg_attempts * config.exploitation_episodes):.1%}")
        
        if success_count >= 4:  # At least 4/5 checks should pass
            print(f"üéâ Multi-Attempt + HER Enhanced Training: WORKING")
            return True
        else:
            print(f"‚ö†Ô∏è  Multi-Attempt + HER Enhanced Training: NEEDS ATTENTION")
            return False
            
    except Exception as e:
        print(f"\n‚ùå Test failed with error: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_multi_attempt_training()
    exit(0 if success else 1) 